# 32VGG+LRN 우분투에러수정Model
import tensorflow as tf
import os

def predict():


def isFire(*Tinput):
    print(tf.__version__)
    XInput = Tinput[0]
    print(XInput)

    tf.set_random_seed(777)

    image_depth = 2

    # lrn(2, 2e-05, 0.75, name='norm1')
    radius = 2
    alpha = 2e-05
    beta = 0.75
    bias = 1.0


    # ---------------------------------------------------------------------------------------------------
    # X: input 32*32*image_depth
    # Y: output '1' or '0'
    X = tf.placeholder(tf.float32, [32 * 32 * image_depth])
    Y = tf.placeholder(tf.int32, [1])  # 0,1

    # 출력 class 개수 = 1(fire), 0(not fire)
    nb_classes = 2

    # one hot & reshape
    Y_one_hot = tf.one_hot(Y, nb_classes)  # print("one_hot", Y_one_hot)
    Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])  # print("reshape", Y_one_hot)

    # img 32x32x1 (black/white)
    X_img = tf.reshape(X, [-1, 32, 32, image_depth])

    # ---------------------------------------------------------------------------------------------------
    # L1 ImgIn shape = (?, 32, 32, image_depth)
    W1 = tf.Variable(tf.random_normal([3, 3, image_depth, 64], stddev=0.01))

    # Conv1 -> (?, 32, 32, 64)
    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')

    # Conv2 -> (?, 32, 32, 64)
    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')
    L1 = tf.nn.relu(L1)

    # lrn1
    # lrn(2, 2e-05, 0.75, name='norm1')
    L1 = tf.nn.local_response_normalization(L1, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)

    # Pool -> (?, 16, 16, 64)
    L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

    # ---------------------------------------------------------------------------------------------------
    # L2 ImgIn shape = (?, 16, 16, 64)
    W2 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))

    # Conv1 -> (?, 16, 16, 128)
    L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')

    # Conv2 -> (?, 16, 16, 128)
    L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')
    L2 = tf.nn.relu(L2)

    # lrn2
    # lrn(2, 2e-05, 0.75, name='norm1')
    L2 = tf.nn.local_response_normalization(L2, depth_radius=radius, alpha=alpha, beta=beta, bias=bias)

    # Pool -> (?, 8, 8, 128)
    L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

    # ---------------------------------------------------------------------------------------------------
    # L3 ImgIn shape = (?, 8, 8, 128)
    W3 = tf.Variable(tf.random_normal([3, 3, 128, 256], stddev=0.01))

    # Conv1 -> (?, 8, 8, 256)
    L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')

    # Conv2 -> (?, 8, 8, 256)
    L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')

    # Conv3 -> (?, 8, 8, 256)
    L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')
    L3 = tf.nn.relu(L3)

    # Pool -> (?, 4, 4, 256)
    L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

    # ---------------------------------------------------------------------------------------------------
    # L4 ImgIn shape = (?, 4, 4, 256)
    W4 = tf.Variable(tf.random_normal([3, 3, 256, 512], stddev=0.01))

    # Conv1 -> (?, 4, 4, 512)
    L4 = tf.nn.conv2d(L3, W4, strides=[1, 1, 1, 1], padding='SAME')

    # Conv2 -> (?, 4, 4, 512)
    L4 = tf.nn.conv2d(L3, W4, strides=[1, 1, 1, 1], padding='SAME')

    # Conv3 -> (?, 4, 4, 512)
    L4 = tf.nn.conv2d(L3, W4, strides=[1, 1, 1, 1], padding='SAME')
    L4 = tf.nn.relu(L4)

    # Pool -> (?, 2, 2, 512)
    L4 = tf.nn.max_pool(L4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

    # ---------------------------------------------------------------------------------------------------
    # L5 ImgIn shape = (?, 2, 2, 512)
    W5 = tf.Variable(tf.random_normal([2, 2, 512, 512], stddev=0.01))

    # Conv1 -> (?, 2, 2, 512)
    L5 = tf.nn.conv2d(L4, W5, strides=[1, 1, 1, 1], padding='SAME')

    # Conv2 -> (?, 2, 2, 512)
    L5 = tf.nn.conv2d(L4, W5, strides=[1, 1, 1, 1], padding='SAME')

    # Conv3 -> (?, 2, 2, 512)
    L5 = tf.nn.conv2d(L4, W5, strides=[1, 1, 1, 1], padding='SAME')
    L5 = tf.nn.relu(L5)

    # Pool -> (?, 1, 1, 512)
    L5 = tf.nn.max_pool(L5, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

    # Reshape -> (?, 1 * 1 * 512) - Flatten them for FC
    L5_flat = tf.reshape(L5, [-1, 1 * 1 * 512])

    # ---------------------------------------------------------------------------------------------------
    # L6 FC 1x1x512 inputs ->  4096 outputs
    W6 = tf.get_variable("W6", shape=[512 * 1 * 1, 4096], initializer=tf.contrib.layers.xavier_initializer())
    b6 = tf.Variable(tf.random_normal([4096]))
    L6 = tf.nn.relu(tf.matmul(L5_flat, W6) + b6)

    # ---------------------------------------------------------------------------------------------------
    # L7 FC 4096 inputs ->  1000 outputs
    W7 = tf.get_variable("W7", shape=[4096, 1000], initializer=tf.contrib.layers.xavier_initializer())
    b7 = tf.Variable(tf.random_normal([1000]))
    L7 = tf.nn.relu(tf.matmul(L6, W7) + b7)

    # ---------------------------------------------------------------------------------------------------
    # L8 FC 1000 inputs -> 1 outputs
    W8 = tf.get_variable("W8", shape=[1000, nb_classes], initializer=tf.contrib.layers.xavier_initializer())
    b8 = tf.Variable(tf.random_normal([nb_classes]))
    logits = tf.matmul(L7, W8) + b8




    # ---------------------------------------------------------------------------------------------------
    # initialize

    init = tf.global_variables_initializer()
    sess = tf.Session()
    sess.run(init)

    # ---------------------------------------------------------------------------------------------------
    # predict
    # print(os.getcwd() + "/ISFire(new model).ckpt")
    save_path = os.getcwd() + "/ISFire(new model).ckpt"
    # ckpt = tf.train.get_checkpoint_state(os.getcwd())

    # with tf.Session() as sess:
    # saver.restore(sess,save_path)
    # saver.restore(sess, tf.train.latest_checkpoint(save_path))

    saver = tf.train.Saver()
    saver.restore(sess, save_path)


    prediction = tf.argmax(logits, 1)
    predict_output = sess.run(prediction, feed_dict={X: XInput})
    sess.close()

    print(predict_output)
    return predict_output


tup = ((76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85,
        76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85,
        76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85,
        76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85,
        76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 120, 49, 120, 49, 121, 50, 121,
        50, 121, 50, 121, 50, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43,
        120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 115, 175, 115, 175, 116, 72, 116, 72, 119, 59, 119, 59, 121, 47,
        121, 47, 121, 42, 76, 85, 76, 85, 120, 49, 120, 49, 121, 50, 121, 50, 121, 50, 121, 50, 120, 43, 120, 43, 120,
        43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43,
        115, 175, 115, 175, 116, 72, 116, 72, 119, 59, 119, 59, 121, 47, 121, 47, 121, 42, 76, 85, 76, 85, 120, 48, 120,
        48, 121, 49, 121, 49, 121, 49, 121, 49, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43,
        120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 121, 43, 121, 43, 120, 49, 120, 49, 118, 59, 118,
        59, 116, 66, 116, 66, 116, 67, 76, 85, 76, 85, 120, 48, 120, 48, 121, 47, 121, 47, 121, 47, 121, 47, 120, 43,
        120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120,
        43, 120, 43, 121, 48, 121, 48, 121, 47, 121, 47, 121, 46, 121, 46, 120, 49, 120, 49, 118, 53, 76, 85, 76, 85,
        120, 48, 120, 48, 121, 47, 121, 47, 121, 47, 121, 47, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120,
        43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 121, 48, 121, 48, 121, 47, 121, 47,
        121, 46, 121, 46, 120, 49, 120, 49, 118, 53, 76, 85, 76, 85, 120, 47, 120, 47, 121, 46, 121, 46, 121, 46, 121,
        46, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43,
        120, 43, 120, 43, 120, 43, 121, 48, 121, 48, 120, 47, 120, 47, 121, 45, 121, 45, 120, 46, 120, 46, 119, 49, 76,
        85, 76, 85, 121, 47, 121, 47, 121, 45, 121, 45, 121, 45, 121, 45, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43,
        120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 121, 44, 121, 44, 120,
        46, 120, 46, 120, 47, 120, 47, 119, 49, 119, 49, 118, 48, 76, 85, 76, 85, 121, 47, 121, 47, 121, 45, 121, 45,
        121, 45, 121, 45, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120,
        43, 120, 43, 120, 43, 120, 43, 120, 43, 121, 44, 121, 44, 120, 46, 120, 46, 120, 47, 120, 47, 119, 49, 119, 49,
        118, 48, 76, 85, 76, 85, 121, 46, 121, 46, 121, 45, 121, 45, 121, 45, 121, 45, 120, 43, 120, 43, 120, 43, 120,
        43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 48,
        120, 48, 120, 46, 120, 46, 120, 42, 120, 42, 120, 41, 120, 41, 120, 41, 76, 85, 76, 85, 121, 47, 121, 47, 121,
        46, 121, 46, 121, 45, 121, 45, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43,
        120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 40, 120, 40, 120, 42, 120, 42, 120, 42, 120, 42, 119,
        46, 119, 46, 118, 48, 76, 85, 76, 85, 121, 47, 121, 47, 121, 46, 121, 46, 121, 45, 121, 45, 120, 43, 120, 43,
        120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120,
        43, 120, 40, 120, 40, 120, 42, 120, 42, 120, 42, 120, 42, 119, 46, 119, 46, 118, 48, 76, 85, 76, 85, 121, 47,
        121, 47, 121, 46, 121, 46, 121, 46, 121, 46, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120,
        43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 46, 120, 46, 120, 44, 120, 44, 120, 42,
        120, 42, 120, 41, 120, 41, 119, 41, 76, 85, 76, 85, 119, 45, 119, 45, 119, 45, 119, 45, 119, 43, 119, 43, 121,
        47, 121, 47, 121, 47, 121, 47, 121, 47, 121, 47, 121, 46, 121, 46, 121, 46, 121, 45, 121, 45, 121, 45, 121, 45,
        121, 43, 121, 43, 120, 45, 120, 45, 120, 44, 120, 44, 120, 43, 120, 43, 119, 42, 119, 42, 119, 41, 76, 85, 76,
        85, 119, 45, 119, 45, 119, 45, 119, 45, 119, 43, 119, 43, 121, 47, 121, 47, 121, 47, 121, 47, 121, 47, 121, 47,
        121, 46, 121, 46, 121, 46, 121, 45, 121, 45, 121, 45, 121, 45, 121, 43, 121, 43, 120, 45, 120, 45, 120, 44, 120,
        44, 120, 43, 120, 43, 119, 42, 119, 42, 119, 41, 76, 85, 76, 85, 119, 45, 119, 45, 119, 45, 119, 45, 119, 44,
        119, 44, 121, 47, 121, 47, 121, 47, 121, 47, 121, 47, 121, 47, 121, 46, 121, 46, 121, 46, 121, 45, 121, 45, 121,
        45, 121, 45, 121, 45, 121, 45, 120, 45, 120, 45, 120, 44, 120, 44, 120, 43, 120, 43, 119, 42, 119, 42, 119, 41,
        76, 85, 76, 85, 119, 45, 119, 45, 119, 45, 119, 45, 119, 44, 119, 44, 120, 47, 120, 47, 120, 47, 120, 47, 120,
        47, 120, 47, 120, 46, 120, 46, 120, 46, 120, 45, 120, 45, 120, 45, 120, 45, 120, 45, 120, 45, 120, 43, 120, 43,
        120, 44, 120, 44, 120, 43, 120, 43, 119, 42, 119, 42, 119, 41, 76, 85, 76, 85, 119, 45, 119, 45, 119, 45, 119,
        45, 119, 44, 119, 44, 120, 47, 120, 47, 120, 47, 120, 47, 120, 47, 120, 47, 120, 46, 120, 46, 120, 46, 120, 45,
        120, 45, 120, 45, 120, 45, 120, 45, 120, 45, 120, 43, 120, 43, 120, 44, 120, 44, 120, 43, 120, 43, 119, 42, 119,
        42, 119, 41, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 76, 85, 119, 46, 119, 46,
        119, 46, 119, 46, 119, 46, 119, 46, 119, 46, 119, 45, 119, 45, 119, 45, 119, 45, 119, 45, 119, 45, 120, 43, 120,
        43, 120, 43, 120, 43, 120, 43, 120, 43, 119, 42, 119, 42, 119, 41, 76, 85, 76, 85, 119, 45, 119, 45, 119, 45,
        119, 45, 119, 43, 119, 43, 76, 85, 76, 85, 119, 46, 119, 46, 119, 46, 119, 46, 119, 45, 119, 45, 119, 45, 119,
        45, 119, 45, 119, 45, 119, 45, 119, 45, 119, 45, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 41,
        120, 41, 119, 41, 76, 85, 76, 85, 119, 45, 119, 45, 119, 45, 119, 45, 119, 43, 119, 43, 76, 85, 76, 85, 119, 46,
        119, 46, 119, 46, 119, 46, 119, 45, 119, 45, 119, 45, 119, 45, 119, 45, 119, 45, 119, 45, 119, 45, 119, 45, 120,
        43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 41, 120, 41, 119, 41, 76, 85, 76, 85, 119, 43, 119, 43,
        119, 43, 119, 43, 119, 42, 119, 42, 76, 85, 76, 85, 118, 43, 118, 43, 118, 43, 118, 43, 118, 43, 118, 43, 118,
        43, 118, 43, 118, 43, 118, 43, 118, 43, 118, 43, 118, 43, 120, 43, 120, 43, 120, 43, 120, 43, 120, 42, 120, 42,
        120, 41, 120, 41, 119, 41, 76, 85, 76, 85, 119, 42, 119, 42, 120, 42, 120, 42, 119, 41, 119, 41, 76, 85, 76, 85,
        117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117,
        42, 120, 43, 120, 43, 120, 43, 120, 43, 120, 42, 120, 42, 120, 41, 120, 41, 119, 40, 76, 85, 76, 85, 119, 42,
        119, 42, 120, 42, 120, 42, 119, 41, 119, 41, 76, 85, 76, 85, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117,
        42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 117, 42, 120, 43, 120, 43, 120, 43, 120, 43, 120, 42,
        120, 42, 120, 41, 120, 41, 119, 40, 76, 85, 76, 85, 120, 42, 120, 42, 120, 41, 120, 41, 120, 40, 120, 40, 76,
        85, 76, 85, 118, 41, 118, 41, 118, 41, 118, 41, 118, 42, 118, 42, 118, 42, 118, 42, 118, 42, 118, 42, 118, 42,
        118, 42, 118, 42, 120, 42, 120, 42, 120, 43, 120, 43, 120, 42, 120, 42, 120, 41, 120, 41, 119, 40, 76, 85, 76,
        85, 118, 39, 118, 39, 118, 39, 118, 39, 118, 39, 118, 39, 76, 85, 76, 85, 119, 41, 119, 41, 119, 41, 119, 41,
        119, 41, 119, 41, 119, 42, 119, 42, 119, 42, 119, 42, 119, 42, 119, 42, 119, 42, 120, 41, 120, 41, 120, 40, 120,
        40, 120, 40, 120, 40, 120, 39, 120, 39, 119, 39, 76, 85, 76, 85, 118, 39, 118, 39, 118, 39, 118, 39, 118, 39,
        118, 39, 76, 85, 76, 85, 119, 41, 119, 41, 119, 41, 119, 41, 119, 41, 119, 41, 119, 42, 119, 42, 119, 42, 119,
        42, 119, 42, 119, 42, 119, 42, 120, 41, 120, 41, 120, 40, 120, 40, 120, 40, 120, 40, 120, 39, 120, 39, 119, 39,
        76, 85, 76, 85, 119, 39, 119, 39, 118, 39, 118, 39, 118, 38, 118, 38, 76, 85, 76, 85, 119, 40, 119, 40, 119, 41,
        119, 41, 119, 41, 119, 41, 119, 41, 119, 41, 119, 41, 119, 41, 119, 41, 119, 42, 119, 42, 120, 40, 120, 40, 120,
        39, 120, 39, 120, 39, 120, 39, 119, 39, 119, 39, 119, 38, 76, 85, 76, 85, 118, 37, 118, 37, 118, 37, 118, 37,
        118, 37, 118, 37, 76, 85, 76, 85, 118, 39, 118, 39, 118, 39, 118, 39, 118, 39, 118, 39, 118, 40, 118, 40, 118,
        40, 118, 40, 118, 40, 118, 40, 118, 40, 120, 39, 120, 39, 120, 39, 120, 39, 119, 39, 119, 39, 119, 38, 119, 38,
        118, 37, 76, 85, 76, 85, 118, 37, 118, 37, 118, 37, 118, 37, 118, 37, 118, 37, 76, 85, 76, 85, 118, 39, 118, 39,
        118, 39, 118, 39, 118, 39, 118, 39, 118, 40, 118, 40, 118, 40, 118, 40, 118, 40, 118, 40, 118, 40, 120, 39, 120,
        39, 120, 39, 120, 39, 119, 39, 119, 39, 119, 38, 119, 38, 118, 37, 76, 85, 76, 85, 118, 37, 118, 37, 118, 36,
        118, 36, 118, 36, 118, 36, 76, 85, 76, 85, 118, 37, 118, 37, 118, 39, 118, 39, 118, 39, 118, 39, 118, 39, 118,
        39, 118, 39, 118, 39, 118, 39, 118, 40, 118, 40, 120, 39, 120, 39, 119, 39, 119, 39, 119, 39, 119, 39, 119, 38,
        119, 38, 118, 37),)

#print(isFire(tup))
